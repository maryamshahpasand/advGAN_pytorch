import torch
import numpy as np
import dataload
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import models
from models import malware_classifier_net

use_cuda=True
image_nc=1
batch_size = 128
hidden_size = 200
# niose_size = 100
output_size=1
gen_input_nc = image_nc

# Define what device we are using
print("CUDA Available: ",torch.cuda.is_available())
device = torch.device("cuda" if (use_cuda and torch.cuda.is_available()) else "cpu")




# test adversarial examples in Drebin training dataset
# mnist_dataset = torchvision.datasets.MNIST('./dataset', train=True, transform=transforms.ToTensor(), download=True)
# train_dataloader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=False, num_workers=1)
train_laoder, feature_vectore_size = dataload.load_data(train=True)

# load the pretrained model
pretrained_model = "./malware_classifier_net.pth"
target_model = malware_classifier_net(input_size=feature_vectore_size, hidden_size=hidden_size, output_size=output_size).to(device)
target_model.load_state_dict(torch.load(pretrained_model))
target_model.eval()

# load the generator of adversarial examples
pretrained_generator_path = './models/net_malG_epoch_60.pth'
pretrained_G = models.Mal_Generator(input_size=feature_vectore_size, hidden_size=hidden_size, output_size=feature_vectore_size).to(device)
pretrained_G.load_state_dict(torch.load(pretrained_generator_path))
pretrained_G.eval()


num_correct = 0
for i, data in enumerate(train_laoder, 0):
    test_mal, test_label = data
    test_mal, test_label = test_mal.to(device), test_label.to(device)
    xmal_batch = test_mal[(test_label != 0).nonzero()]
    if (len(xmal_batch.shape) > 2):
        xmal_batch = xmal_batch.reshape((xmal_batch.shape[0] * xmal_batch.shape[1]), xmal_batch.shape[2])

    perturbation =  torch.where(pretrained_G(xmal_batch.float())>0.5 , torch.ones_like(xmal_batch), torch.zeros_like(xmal_batch))
    # perturbation = torch.clamp(perturbation, -0.3, 0.3)
    adv_mal = torch.max(xmal_batch,perturbation)
    # adv_mal = torch.clamp(adv_mal, 0, 1)
    pred_lab = target_model(adv_mal.float())
    pred_lab[pred_lab < 0.5] = 0
    pred_lab[pred_lab >= 0.5] = 1
    num_correct += torch.sum((pred_lab==torch.ones(pred_lab.shape[0]).float().cuda())[0])

print('Drebin training dataset:')
print('num_correct: ', num_correct.item())
print('accuracy of adv mal in training set: %f\n'%(num_correct.item()/len(train_laoder.dataset)/2))

# test adversarial examples in MNIST testing dataset
test_dataloader, feature_vectore_size = dataload.load_data(train=False)

num_correct = 0
for i, data in enumerate(test_dataloader, 0):
    test_mal, test_label = data
    test_mal, test_label = test_mal.to(device), test_label.to(device)

    xmal_batch = test_mal[(test_label != 0).nonzero()]
    # if (len(xmal_batch.shape) > 2):
    #     xmal_batch = xmal_batch.reshape((xmal_batch.shape[0] * xmal_batch.shape[1]), xmal_batch.shape[2])

    perturbation = pretrained_G(xmal_batch.float())
    # perturbation = torch.clamp(perturbation, -0.3, 0.3)
    adv_mal = torch.where(torch.max(xmal_batch,perturbation.long())>0.5 , torch.ones_like(xmal_batch), torch.zeros_like(xmal_batch))
    # adv_mal = torch.clamp(adv_mal, 0, 1)
    pred_lab = target_model(adv_mal.float())
    pred_lab[pred_lab < 0.5] = 0
    pred_lab[pred_lab >= 0.5] = 1
    num_correct += torch.sum((pred_lab==torch.ones(pred_lab.shape[0]).float().cuda())[0])

print('num_correct: ', num_correct.item())
print('accuracy of adv mal in testing set: %f\n'%(num_correct.item()/len(test_dataloader.dataset)/2))

